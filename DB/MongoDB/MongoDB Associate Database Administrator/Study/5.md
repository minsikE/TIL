# 5주차

## Unit 13. MongoDB Database Metrics & Monitoring

### Lesson 1. Core Metrics
- What we should monitor
    - Baseline value
    - Burst value
    - Out of range

#### Core metrics

- Query targeting
    - Read efficiency
    - Ideal ratio is 1
        - Every document scanned was returned
        - As the ratio increases, the efficiency of the query decreases.
    - A very high ratio negatively impacts the system performance.
    
    ![QueryTargeting](resources/QueryTargeting.png)
    
    - The blue line shows the ratio of index keys scanned to documents returned.
    - The green line is the ratio of documents scanned to documents returned.
    - This chart shows that read operations are right around the ideal ratio of one to one.
- Storage
    - Monitor disk usage
    - Writes are refused once the storage capacity is reached and the affected MongoDB instances could crash.
    - Key Metrics
        - Disk Space Percent Free
            
            ![DiskSpacePercentFree](resources/DiskSpacePercentFree.png)
            
        - Disk IOPS (input/output operations per second)
            
            ![DiskIOPS](resources/DiskIOPS.png)
            
        - Disk Queue Depth
            
            ![DiskQueueDepth](resources/DiskQueueDepth.png)
            
        - Disk Latency
            
            ![DiskLatency](resources/DiskLatency.png)
            
- CPU utilization
    - Track CPU usage by deployment
    - System CPU
        
        ![SystemCPU](resources/SystemCPU.png)
        
    - Process CPU
        
        ![ProcessCPU](resources/ProcessCPU.png)
        
    - Prolonged high CPU usage can lead to operation delays
    - Optimize query performance with indexes
- Memory utilization
    - Amount of system memory available for your workloads
    - System sized to hold all indexes
    - Performance issues or Out Of Memory(OOM)
    - Key Metrics:
        - System Memory
            
            ![SystemMemory](resources/SystemMemory.png)
            
        - Swap Usage
            
            ![SwapUsage](resources/SwapUsage.png)
            
- Replication lag
    - Measures delay between the primary and the secondary
    - Expressed in seconds
    - Negatively impacts elections and distributed read consistency
        
        ![ReplicationLag](resources/ReplicationLag.png)
        

##### Baseline values:

- Varies depending on workload
- Establish by sampling metrics during steady workload

##### Burst values

- Normal to have occasional spikes
- Excessive spiking or sustained spikes could indicate an issue

##### Out of range

- Query Targeting:
    - Very high raio
- Replication lag
    - A secondary is unable to keep up with a primary
- Rest of metrics
    - Resource exhaustion, 90% or above

---

#### Quiz

1. **Which of the following is the ideal value for objects scanned when reviewing the Query Targeting metrics? (Select one.)**
- **a.** 1
    
    **Correct.**
    
    The ideal ratio of scanned objects to documents returned is about 1:1.
    
- **b.** 100
    
    **Incorrect.**
    
    This value indicates that 100 objects were scanned and 1 was returned. Ideally, we want a ratio of about 1:1.
    
- **c.** 1000
    
    **Incorrect.**
    
    This value indicates that 1000 objects were scanned and 1 was returned. Ideally, we want a ratio of about 1:1.
    
- **d.** 10000
    
    **Incorrect.**
    
    This value indicates that 10000 objects were scanned and 1 was returned. Ideally, we want a ratio of about 1:1.
    

2. **You need to check if the storage subsystem has become a bottleneck. Which of the following storage metrics will help you determine if operations are waiting to be serviced? (Select one.)**
- **a.** Swap Usage
    
    **Incorrect.**
    
    Swap Usage is a metric that is used to determine how much memory is being placed on the swap device. If we want to determine if operations are waiting to be serviced, we should look at Disk Queue Depth.
    
- **b.** Disk Queue Depth
    
    **Correct.**
    
    Disk Queue Depth tells us the average length of the queue of requests issued to the disk partition used by MongoDB. This metric will indicate whether or not operations are waiting to be serviced.
    
- **c.** System CPU
    
    **Incorrect.** System CPU displays the CPU usage of all processes on the node. If we want to determine if operations are waiting to be serviced, we should look at Disk Queue Depth.
    
- **d.** Disk Space Percent Free
    
    **Incorrect.**
    
    Disk Space Percent Free tells us the percentage of free disk space on the partition used by MongoDB. If we want to determine if operations are waiting to be serviced, we should look at Disk Queue Depth.

### Lesson 2. More Metrics
#### Additional metrics

##### Opcounters

- Number of operations per second run on a MongoDB process since the last restart
- Operations
    - command
    - query
    - insert
    - delete
    - update
    - getMore
- Example

![Opcounters](resources/Opcounters.png)

##### Network traffic

- Average rate of physical bytes sent to and from the database server per second over the selected time range
- Excessive traffic affects performance
- Example
    
    ![NetworkTraffic](resources/NetworkTraffic.png)
    
    - The blue line represents bytes in, or the average rate of physical bytes sent to the database.
    - The green line represents bytes out, or the average rate of physical bytes sent from the database.
    - The light green line at the top represents num requests, or the average number of requests sent to the database.

##### Connections

- Total number of open connections to the database by application, shell clients, as well as internal MongoDB connections
- Excessive connections can affect system performance.
- May indicate a suboptimal client connection strategy.
- Example
    
    ![Connections](resources/Connections.png)
    

##### Tickets available

- Number of read and write operations available to the MongoDB storage engine
- When available tickets drop to zero, other operations must wait until one of the running operations completes and frees up a ticket
- Slowdown of operations will impact application performance and is indicative of an undersized cluster or poorly performing queries.

![TicketsAvailable](resources/TicketsAvailable.png)

- The default limit for read and write tickets is 128, so we’re doing great.

---

#### Quiz

1. **Which of the following metrics allows you to view the rate at which different types of operations are being performed within your deployment? (Select one.)**
- **a.** Tickets Available
    
    **Incorrect.**
    
    Tickets Available indicates the number of concurrent read and write operations available to the MongoDB storage engine. In this case, we would check Opcounters to view the rate at which different operations are being performed.
    
- **b.** Network Traffic
    
    **Incorrect.**
    
    Network Traffic metrics provide information about your network performance and include bytesIn, bytesOut, and NumRequests. In this case, we would check Opcounters to view the rate at which different operations are being performed.
    
- **c.** Connections
    
    **Incorrect.**
    
    Connections represent the total number of open network connections to the database deployment by application, shell clients, as well as internal MongoDB connections. In this case, we would check Opcounters to view the rate at which different operations are being performed.
    
- **d.** Opcounters
    
    **Correct.**
    
    Opcounters measures the rate at which operations are performed which can help correlate changes in operations with your MongoDB deployment’s performance.
    
2. **Which of the following metrics should you watch if you wish to monitor network traffic for your deployment? (Select all that apply.)**
- **a.** bytesIn
    
    **Correct.**
    
    bytesIn displays the average rate of physical bytes (after any wire compression) sent to the database server per second over the selected sample period.
    
- **b.** bytesOut
    
    **Correct.**
    
    bytesOut displays the average rate of physical bytes (after any wire compression) sent from the database server per second over the selected sample period.
    
- **c.** numRequests
    
    **Correct.**
    
    numRequests displays the average rate of requests sent to the database server per second over the selected sample period.
    
- **d.** Tickets Available
    
    **Incorrect.**
    
    Tickets Available is a metric that indicates the number of concurrent read and write operations available to the WiredTiger storage engine and will not help with monitoring network traffic.

### Lesson 3. Monitoring M10+
#### View and analyze metrics using

##### Metrics tab

- View the metrics for an Atlas cluster
- After selecting a cluster, you can view the metrics for `a replica set` or `a single node`.
- Free/Shared Clusters
    - Connections
    - Network
    - Opcounters
    - Logical Size
- M10+ Clusters
    - More than 40 metrics
    - View, toggle, and analyze charts

##### Real-Time

- View real-time performance metrics for an M10+ Atlas cluster
- Hardware metrics
    - CPU
    - Disk Utilization
    - System Memory
- Connection and Network traffic Metrics
- Query Performance
    - Operations
    - Query executions times
    - Query Targeting
    - Read & Writes
- Hottest Collections
- Slowest Operations
    - Can terminate a slow operation by the KILL OP button

#### Retrieve metrics using the Atlas CLI

```jsx
atlas metrics processes <hostname:port> <options>
```

```jsx
atlas metrics processes staging-shard-00-01.xwgj1.mongodb.net:27017 \
--period P1D \
--granularity PT5M \
--output json \
--type CONNECTIONS
```

```jsx
# Run the following Atlas CLI command to return all running processes for your project:
atlas processes list

# Retrieve Process Metrics
# Run the following Atlas CLI command to retrieve connection metrics for one cluster node.

atlas metrics processes <cluster id>  
--period P1D --granularity PT5M --output json –type connections
```

---

#### Quiz

1. **Given the following Real-Time Performance Panel metrics displayed, how many connections are currently active? (Select one.)**

![MonitoringM10+Quiz1](resources/MonitoringM10+Quiz1.png)

- **a.** 15
    
    **Incorrect.**
    
    The number of active connections for this deployment is 47, and can be found at the top of the Real-Time Performance Panel.
    
- **b.** 100.3
    
    **Incorrect.**
    
    The number of active connections for this deployment is 47, and can be found at the top of the Real-Time Performance Panel.
    
- **c.** 0
    
    **Incorrect.**
    
    The number of active connections for this deployment is 47, and can be found at the top of the Real-Time Performance Panel.
    
- **d.** 47
    
    **Correct.**
    
    47 connections are currently active, which is well under the 1500 limit for an M10 cluster.
    
2. **MongoDB Atlas supports more than 40 metrics for M10+ clusters only.**
- **a.** True
    
    **Correct.**
    
    Free and Shared clusters have access to metrics related to connections, network, logical size, and Opcounters, while M10 and above clusters have access to more than 40 metrics.
    
- **b.** False
    
    **Incorrect.**
    
    Free and Shared clusters have access to metrics related to connections, network, logical size, and Opcounters, while M10 and above clusters have access to more than 40 metrics.

### Lesson 4. Configure Alerts
- Confire different alert settings at the Organization and Project levels
- Must have the “Project Owner” role to configure Project alert settings

#### Shared-tier cluster:

- Connections
- Logical size
- Opcounters
- Network

#### Project Alert Settings

- Projects are created with a set of default alert settings
- Modify the default alert settings

![AlertSettings1](resources/AlertSettings1.png)

![AlertSettingsEdit](resources/AlertSettingsEdit.png)

- Create your own

![AlertCreate](resources/AlertCreate.png)

#### Atlas CLI

```jsx
# View Alert Settings
atlas alerts settings list --output json

# Create a New Alert

atlas alerts settings create \
--event JOINED_GROUP \
--enabled \
--notificationIntervalMin 5 \
--notificationType USER \
--notificationEmailEnabled \
--notificationUsername luke.phillippi@mongodb.com \
--output json \
--projectId 5bf2dce0a6f239c68079ad39

# Update Alert Settings

atlas alerts settings update 64c3f855ce2d504de0d43dc3 \
--event JOINED_GROUP \
--enabled \
--notificationIntervalMin 5 \
--notificationType USER \
--notificationEmailEnabled \
--notificationUsername luke.phillippi+atlas@mongodb.com \
--output json \
--projectId 5bf2dce0a6f239c68079ad39

# Delete an Alert
atlas alerts settings delete 64c3f855ce2d504de0d43dc3
```

---

#### Quiz

1. **You are creating new alerts for an M5 (shared-tier) cluster and you successfully configure an alert for a Query Targeting metric. However, you notice that the alert isn’t being triggered, even though several queries are exceeding the threshold you set. Which of the following explains why the new alert isn’t being triggered? (Select one.)**
- **a.** The Query Targeting alert condition cannot be configured to be different from the default threshold.
    
    **Incorrect.**
    
    Alert conditions for any metric can be configured to be different from the default settings across all cluster tiers, however, shared-tier clusters will only trigger alerts related to the metrics supported by those clusters, including Network, Connections, Logical Size, and Opcounters.
    
- **b.** The Query Target alert condition will not trigger an alert for an M5 cluster.
    
    **Correct.**
    
    Alerts can be configured for any metric across all cluster tiers, however, shared-tier clusters will only trigger alerts related to the metrics supported by those clusters, including Network, Connections, Logical Size, and Opcounters.
    
- **c.** Alerts cannot be configured for Query Targeting metrics.
    
    **Incorrect.**
    
    Alerts can be configured for any metric across all cluster tiers, however, shared-tier clusters will only trigger alerts related to the metrics supported by those clusters, including Network, Connections, Logical Size, and Opcounters.
    
2. **You have been granted the `clusterAdmin` role, will you be able to configure new alert conditions for a specific host? (Select one.)**
- **a.** Yes, the clusterAdmin role provides the greatest cluster admin access and will allow you to configure new alerts for a specific host.
    
    **Incorrect.**
    
    While it is true that the `clusterAdmin` role provides the greatest cluster admin access, you will not be able to configure new alerts without the Project Owner role.
    
- **b.** No, the Project Owner role is required to configure any new alerts for a specific host.
    
    **Correct.**
    
    You must have the Project Owner role in order to successfully configure new alerts for a specific host.

### Lesson 5. Respond to Alerts
#### Atlas UI

- The acknowledgement period ends
    
    ![AcknowledgementAlert](resources/AcknowledgementAlert.png)
    
- You resolve the alert condition
- You unacknowledge the alert
    
    ![UnacknowledgeAlert](resources/UnacknowledgeAlert.png)
    

#### Atlas CLI

- **View Alerts**
    - `atlas alerts list --output json`

```jsx
atlas alerts list --status OPEN --output json
```

- **Acknowledge an Alert**
    - `atlas alerts acknowledge <alertId> --comment <comment>`

```jsx
atlas alerts acknowledge 64c96d04a761000ddc9bb8e8 --until '2028-01-01T00:00:00Z' --comment 'Investigating...'
```

- **Unacknowledge an Alert**
    - `atlas alerts unacknowledge <alertId>`

```jsx
atlas alerts unacknowledge 64c96d04a761000ddc9bb8e8
```

---

#### Quiz

1. **You receive a notification from Atlas that an alert has been triggered for your project and you wish to acknowledge the alert with the Atlas CLI. What information is required to successfully acknowledge the alert with the `atlas alerts acknowledge` command? (Select one.)**
- **a.** metricName
    
    **Incorrect.**
    
    You cannot provide `metricName` as an option when acknowledging an alert. The `atlas alerts acknowledge` command requires `id` to successfully acknowledge an alert.
    
- **b.** comment
    
    **Incorrect.**
    
    `comment` is optional when acknowledging an alert. The `atlas alerts acknowledge` command requires `id` to successfully acknowledge an alert.
    
- **c.** hostnameAndPort
    
    **Incorrect.**
    
    You cannot provide `hostnameAndPort` as an option when acknowledging an alert. The `atlas alerts acknowledge` command requires `id` to successfully acknowledge an alert.
    
- **d.** id
    
    **Correct.**
    
    The `atlas alerts acknowledge` command requires `id` to successfully acknowledge an alert.
    
2. **Under which of the following circumstances will an Atlas alert’s status change to CLOSED? (Select one.)**
- **a.** When the alert is acknowledged
    
    **Incorrect.**
    
    Acknowledging an alert will not change the status to closed. An alert’s status will only change to CLOSED once the condition that triggered the alert is resolved.
    
- **b.** When an alert is disabled
    
    **Incorrect.**
    
    Disabling an alert will not mark it as CLOSED. An alert’s status will only change to CLOSED once the condition that triggered the alert is resolved.
    
- **c.** When the alert condition is resolved
    
    **Correct.**
    
    An alert’s status will only change to CLOSED once the condition that triggered the alert is resolved.
    
- **d.** When a Project Owner manually changes the alert status
    
    **Incorrect.**
    
    A Project Owner cannot manually close an alert. An alert’s status will only change to CLOSED once the condition that triggered the alert is resolved.

### Lesson 6. Integrations
#### MongoDB Atlas Integrations

- Receive Atlas alerts
- View and analyze performance metrics
- Prometheus, Datadog, PagerDuty, Sumo Logic, Splunk On-Call, Ops Genie, and Custom Webhooks.
    - Prometheus and Datadog available only on M10+
- To view third-party integration settings in Atlas, you must have organization owner or project owner access to the project

##### Prometheus

- Open-source monitoring and alerting platform
- Collects metrics from configured targets at given intervals
- Triggers alerts when it observes specific conditions.
- Install and set up Prometheus
    
    ```bash
    # Update your APT package lists:
    sudo apt update
    # Install the prometheus APT package:
    sudo apt install --yes prometheus
    # Confirm that the prometheus system service is running and enabled by reviewing it’s status:
    sudo systemctl status --full prometheus
    # Check that the Prometheus server is ready to serve traffic:
    curl http://localhost:9090/-/ready
    ```
    

![ProjectIntegrations](resources/ProjectIntegrations.png)

![PrometheusConfiguration](resources/PrometheusConfiguration.png)

![PrometheusConfiguration2](resources/PrometheusConfiguration2.png)

```bash
# On your Prometheus host, append the copied Atlas scrape configuration snippet to the scrape_configs section of the template Prometheus configuration:
sudo nano /etc/prometheus/prometheus.yml
```

```bash
# Restart the prometheus system service to apply the configuration change:
sudo systemctl restart prometheus
# Use the Prometheus server API to confirm that the Atlas deployment targets are present and healthy:
curl http://localhost:9090/api/vi/targets | jq --raw-output '.data.activeTargets[] | .scrapeUrl + " " + .health'
```

##### Grafana

- Open-source web application for interactive visualization and analysis
- Visualize data collected by Prometheus and display it on customizable charts for easy analysis.
- Install and set up Grafana
    
    ```bash
    # Install Grafana on Ubuntu Linux
    ## Install the packages required to install Grafana:
    sudo apt-get install --yes apt-transport-https software-properties-common wget
    ## Download the Grafana repository signing key:
    sudo wget -q -O /usr/share/keyrings/grafana.key https://apt.grafana.com/gpg.key
    ## Add Grafana’s package repository to your APT sources:
    echo "deb [signed-by=/usr/share/keyrings/grafana.key] https://apt.grafana.com stable main" | sudo tee -a /etc/apt/sources.list.d/grafana.list
    ## Update your APT package lists:
    sudo apt update
    ## Install the grafana APT package:
    sudo apt install --yes grafana
    # Start the grafana-server system service:
    sudo systemctl start grafana-server
    # Enable the grafana-server system service so that it automatically starts on boot:
    sudo systemctl enable grafana-server
    # Confirm that the grafana-server system service is running and enabled by reviewing it’s status:
    sudo systemctl status --full grafana-server
    # Check that the Grafana server is healthy:
    curl http://localhost:3000/api/health
    # Run the following to add the Prometheus data source to the Grafana server:
    curl \
    --header 'Content-Type: application/json' \
    --user 'admin:admin' \
    --request 'POST' \
    --data '{"name": "Prometheus", "type": "prometheus", "url": "http://localhost:9090", "access": "proxy"}' \
    http://localhost:3000/api/datasources
    ```
    

![Grafana](resources/Grafana.png)

---

#### Quiz

1. **MongoDB Atlas supports hybrid monitoring solutions via 3rd party integrations.**
- **a.** True
    
    **Correct.**
    
    With Atlas integrations you can create hybrid monitoring solutions to meet the unique needs of your deployment.
    
- **b.** False
    
    **Incorrect.**
    
    MongoDB Atlas does support hybrid monitoring solutions via 3rd party integrations, you can create hybrid monitoring solutions to meet the unique needs of your deployment.
    

2. **MongoDB Atlas provides 3rd party integration services with the following data. (Select all that apply.)**
- **a.** Index suggestions
    
    **Incorrect.**
    
    You can monitor slow queries with third-party services, but those services won’t provide suggestions for indexes. However, MongoDB’s Performance Advisor suggests new indexes to improve query performance based on slow queries.
    
- **b.** Alerts
    
    **Correct.** You can integrate Atlas with third-party monitoring services to receive Atlas alerts in external monitoring services, and to view and analyze performance metrics that Atlas collects about your cluster.
    
- **c.** Query results
    
    **Incorrect.**
    
    You cannot query a MongoDB database with a 3rd-party monitoring service.
    
- **d.** Performance metrics that Atlas collects about your cluster
    
    **Correct.**
    
    You can integrate Atlas with third-party monitoring services to receive Atlas alerts, and to view and analyze performance metrics that Atlas collects about your cluster.
### Lesson 7. Self-Managed Monitoring
![Self-ManagedMonitoring](resources/Self-ManagedMonitoring.png)

#### Percona MongoDB Exporter

- Open source tool that handles metrics from a MongoDB deployment
- Retrieves data from diagnostic commands like server status, by looping over all exposed fields.
- Configure it as a Prometheus target.
- Needs to connect to our deployment as a user
- clusterMonitor role

##### Install Percona MongoDB Exporter on Ubuntu Linux

- Follow these steps to install the Percona MongoDB Exporter tool.
1. Download version 0.39.0 of the Percona MongoDB exporter:

```bash
wget
https://github.com/percona/mongodb_exporter/releases/download/v0.39.0/mongodb_exporter-0.39.0.linux-amd64.tar.gz

```

2. Extract the downloaded tarball:

```bash
tar xvzf mongodb_exporter-0.39.0.linux-amd64.tar.gz
```

3. Move the `mongodb_exporter` binary to the `/usr/local/bin/` directory:

```bash
sudo mv mongodb_exporter-0.39.0.linux-amd64/mongodb_exporter /usr/local/bin/
```

##### Create a New User

- Follow these steps to create a user with sufficient privilege so that Percona MongoDB Exporter can read metrics from the MongoDB deployment.
1. Connect to your local MongoDB instance:

```bash
mongosh
```

2. Switch to the `admin` database within your `mongosh` shell session:

```jsx
use admin
```

3. Create a new database user (`test`) with the `clusterMonitor` role:

```jsx
db.createUser({user: "test",pwd: "testing",roles: [{ role: "clusterMonitor", db: "admin" },{ role: "read", db: "local" }]})

```

4. Exit the `mongosh` shell session:

```jsx
exit
```

##### Create a Service for Percona MongoDB Exporter

- Follow these steps to create a new service for the Percona MongoDB exporter and have it run as the prometheus user.
1. Create a new service file for the `mongodb_exporter`:

```sql
sudo nano /lib/systemd/system/mongodb_exporter.service
```

2. Add the following contents to the new service file:

```yaml
[Unit]
Description=MongoDB Exporter
User=prometheus

[Service]
Type=simple
Restart=always
ExecStart=/usr/local/bin/mongodb_exporter \
--collect-all \
--mongodb.uri=mongodb://test:testing@localhost:27017

[Install]
WantedBy=multi-user.target

```

3. Save and exit.
4. Restart the system daemon to reload the unit files:

```bash
sudo systemctl daemon-reload
```

5. Start the `mongodb_exporter` system service:

```bash
sudo systemctl start mongodb_exporter
```

6. Enable the `mongodb_exporter` system service so that it automatically starts on boot:

```bash
sudo systemctl enable mongodb_exporter
```

7. Confirm that the `mongodb_exporter` system service is running and enabled by reviewing it’s status:

```bash
sudo systemctl status --full mongodb_exporter
```

8. Confirm that MongoDB metrics are being collected and available via the `mongodb_exporter /metrics` endpoint:

```bash
curl http://localhost:9216/metrics
```

##### Configure Percona MongoDB Exporter as a Prometheus Target

1. Open the Prometheus configuration file:

```bash
sudo nano /etc/prometheus/prometheus.yml
```

2. Append the below scrape configuration snippet to the `scrape_configs` section of the template Prometheus configuration:

```yaml
...
scrape_configs:
...
  - job_name: 'mongodb_exporter'
    static_configs:
      - targets: ['localhost:9216']
...

```

3. Restart the `prometheus` system service to apply the configuration change:

```
sudo systemctl restart prometheus
```

4. Use the Prometheus server API to confirm that the local MongoDB exporter target is present and healthy:

```sql
curl http://localhost:9090/api/v1/targets | jq --raw-output '.data.activeTargets[] | .scrapeUrl + " " + .health'

```

5. Now you’re ready to start creating Grafana visualizations using the Prometheus data source!

![GrafanaUi](resources/GrafanaUi.png)

---

#### Quiz

1. **Prometheus gathers metrics from MongoDB Atlas via 3rd party integration but can also be used to collect metrics from a self-managed deployment using the following: (Select one.)**
- **a.** Data Dog
    
    **Incorrect.**
    
    Data Dog is a 3rd Party service that can be used separately from Prometheus to monitor a MongoDB deployment.
    
- **b.** Custom Webhooks
    
    **Incorrect.**
    
    Prometheus doesn’t use custom webhooks to monitor a self-managed MongoDB deployment.
    
- **c.** Grafana
    
    **Incorrect.**Grafana is an open source dashboard application that can display metrics from Prometheus.
    
- **d.** Percona MongoDB Exporter
    
    **Correct.**
    
    We can configure the Percona MongoDB Exporter as a Prometheus target.
    

2. **Which of the following best describes how we can use the third-party tool, Grafana, to monitor a self-managed MongoDB deployment? (Select one.)**
- **a.** We can use it to collect metrics directly from a self-managed MongoDB deployment at given intervals.
    
    **Incorrect.**
    
    We use a service like Prometheus to collect metrics from configured targets, like MongoDB Exporter, at given intervals and trigger alerts when it observes specific conditions. We can use Grafana to ingest database metrics from a data source, like Prometheus, and display it on customizable charts for easy analysis.
    
- **b.** We can configure Grafana as a Prometheus target.
    
    **Incorrect.**
    
    We can configure MongoDB Exporter as a Prometheus target so that Prometheus can make database metrics available to Grafana to display on a dashboard.
    
- **c.** We can use Grafana to ingest database metrics from a data source, like Prometheus, and display it on customizable charts for easy analysis.
    
    **Correct.**
    
    Grafana is an open-source web application that we can use to create interactive visualizations and analyze metrics from a self-managed MongoDB deployment.